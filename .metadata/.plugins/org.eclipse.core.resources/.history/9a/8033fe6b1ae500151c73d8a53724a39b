package tfidf;

import java.io.IOException;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.FileUtil;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.util.ProgramDriver;

import utilities.filesMGR;
import utilities.terms;

/**
 * A driver class to initiate the appropriate job based on the user's input.
 * 
 * @author hero
 */
public class Driver {

	/**
	 * @param args
	 */
	
	public static boolean ligne = true ; 
	
	public static String HADOOP_CLUSTER=null;
	
	public static void main(String[] args) {
        
		int exitCode = -1;
		ProgramDriver pgd = new ProgramDriver();
		
		Configuration conf=new Configuration();
		conf.addResource("/usr/local/hadoop/etc/hadoop/core-site.xml");
		HADOOP_CLUSTER= conf.get("fs.defaultFS");
		
		if(args[0]=="tf-idf-3")
		{
			if((args[4]).equalsIgnoreCase("col")){
				Driver.ligne=false;
			}
		}
		
		
		
		try {
			
			// Add all the join main classes
			pgd.addClass("tf-idf-1", WordFrequenceInDoc.class,
					"TF-IDF 1 --- Word Frequence In Documents");
			pgd.addClass("tf-idf-2", WordCountsForDocs.class,
					"TF-IDF 2 --- Word Counts In Documents");
			pgd.addClass("tf-idf-3", WordsInCorpusTFIDF.class,
					"TF-IDF 3 --- Word in Corpus and TF-IDF");
			
			
			
		
			// Execute the appropriate class
			pgd.driver(args);

			// Success
			exitCode = 0;
		} catch (Throwable e) {
			e.printStackTrace();
		}
		System.exit(exitCode);
	}

}
